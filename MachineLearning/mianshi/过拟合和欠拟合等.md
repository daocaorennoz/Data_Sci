
##  过拟合和欠拟合的概念

### 泛化、偏差以及方差

在讨论过拟合和欠拟合之前，需要先解释一下泛化的概念。
泛化能力是用来评价机器学习模型在面对未知数据时的表现好坏的概念。
面对未知的数据，仍能给出好的预测结果，那么便称该机器学习模型的泛化能力强。
反之则弱。

偏差是指模型忽略了多少数据

方差是指模型对于数据的依赖程度

### 过拟合 OverFitting

过拟合简单来讲，就是训练的模型过分关注训练集中的数据特性，过度学习训练集中的噪声和细节，在训练数据上表现出低偏差，高方差的特点，这意味着训练集中的数据中的噪声和随机波动也被当成特性学习，但在将模型应用到测试集中时，这些特性并不适用于测试集，导致效果很差，预测的偏差很大。

### 欠拟合 UnderFitting

欠拟合简单来讲，就是训练的模型在训练中忽略了数据，已有的模型没有很好的学习数据，导致模型在训练集和测试集上表现都很差。体现出高偏差、低方差的特点，但欠拟合通常不被讨论，因为该现象一般出现在机器学习模型刚刚开始训练时，在评估的时候很容易被发现，而解决方法就是继续训练，或者尝试更换更加合适的机器学习方法。

### 好模型

恰当的模型的特性在于：在训练集和测试集中均有很好的表现，训练时这个临界点很难把控，理论上是测试集和训练集错误率一同下降时，测试集错误率第一次上升的时候。

可以利用该方法来进行训练的停止，但这种方法一般在实践中很难以致用，因为者必须得到测试集的知识，相当于测试集的知识已经被泄漏到了训练过程中去.

通常有两种方法来得到好的模型，防止过拟合：

重采样和保留验证集：

使用重采样来验证模型性能是一种常用的方法：最流行的一种重采样技术是K折交叉验证，指的是在训练数据的子集上训练和测试模型k次，同时建立对于机器学习模型在未知数据上的表现的认知。

验证集是训练数据的子集，在训练数据上选择和调整算法模型的参数之后，在验证集上进行评估，得到一些模型在未知数据上的表现的认知。

#### 交叉验证

交叉验证是机器学习在训练模型和验证模型参数常用的方法，顾名思义，交叉就是重复使用数据，将得到的样本数据进行切分和组合，得到不同的训练集和测试集，某次训练的样本可能试下一次测试的用例，用训练集来训练模型，测试集来验证模型。

交叉验证一般使用在数据不充分的场合。

根据交叉验证的方法，可以分为3类：

1. 简单切分：将数据集按一定比例切分称训练集和测试集，每次训练完之后将样本打乱再重新切分，最后选择损失函数中最优的模型和参数。

2. K折交叉验证：K折交叉验证是指将数据集随机切分为S份，K-1份用来训练模型，剩下的1份用来测试数据; 一轮结束完之后，再次选择K-1份来训练模型，剩下的1份来测试数据;重复n（n < k)轮之后，选择最优的模型和参数.

    在此基础上，衍生出S折重复验证，就是重复多次S折交叉验证

3. 留一交叉验证：这是第二种方法的特例，此时S=N（样本个数），仅留下一个训练样本作为测试，这种情况适用于样本数量非常少的情况，一般样本数 < 50时才会采取这种方法。
    
    在此基础上，衍生出留P交叉验证，就是在数据集中删除p个样本作为训练集，p个样本作为测试集。

还有一种非常特殊的交叉方式，叫做自助法，有m个样本，在m个样本中每次随机抽取1个样本放入训练集，有放回地抽取m次，将未被抽中的样本作为测试集。这种方法适用于样本量极其少的情况下，一般m < 20时会采用。

4. 基于标签的分层交叉验证

用于解决样本不平衡问题，使用StratifiedKFold和StratifiedShuffleSplit 两种方法分层抽样。

- StratifiedKFold 是k-folf的变种，返回分层的折叠，在每个折叠中，样本比例大致与总训练集中相同。
- StratifiedShuffleSplit 是ShuffleSplit的变种，会返回直接的划分，但是划分中样本比例大致与总训练集中相同。

交叉验证的目的是通过多次的交叉验证，用损失函数来度量模型的好坏，从中挑选出最好的模型和参数。

#### EarlyStopping

“早停”不仅是一种规则化技术，而且在训练方向不正确时，它会提供防止资源浪费的机制。

### 超参数的搜索方法

1. 网格搜索方法

    gridsearch：定义一个N维的网格，每个映射代表一个超参数，但这种方法对计算资源消耗很大，
    当维度小于或等于4时，常用这种方法。但是在实践中，即使保证最后找到最佳配置，它仍然不可取，而是应该使用随机搜索。

2. 随机搜索方法

    randomsearch和gridsearch之间唯一的区别在于策略周期的第一步：随机搜索在配置空间上随机选择点。在网格搜索中，即使已经训练了9个模型，通常每个参数只有3个值，但随机搜索中参数值重复的概率非常低，更广泛的探索了参数空间，随机搜索为每个搜索任务提供了很好的基线。

3. 贝叶斯优化

4. 试错法




