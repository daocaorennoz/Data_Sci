
# 核函数 Kernel function

核函数的作用并不是将原始低维不可分特征映射到高维，使得线性可分，这种映射叫做feature space transformation，而是这种映射$\phi(x)$的内积。也就是将低维复杂的计算过程映射到高维得到相较而言比较简单的计算。所以也有个名字叫kernel trick。顾名思义，核函数只是一种计算技巧。降低计算的复杂度，甚至把不可能的计算变成可能。

## 线性核

最简单的核函数：$k(x,y) = x^Ty$

## 多项式核

是一种非标准核函数，非常适合于正交归一化后的数据，具体形式为：$k(x,y) = (ax^Ty + b)^d$

该和函数比较好用，参数比较多，但还算稳定。

## Sigmod 核函数

来源于神经网络，大量应用于深度学习，是S型的，所以被作为激活函数，数学形式为：$k(x,y) = tanh(\alpha x^ty+b)$



## 高斯核

一种经典的鲁棒径向基核，对数据中的噪音有着较好的抗干扰能力，其参数决定了函数作用范围，超过这个范围，数据的作用就基本消失，数学形式为：$k(x,y) = exp(-\frac{||x-y||^2}{2\sigma ^2})$

该核函数被广泛使用，但该核函数的性能对参数比较敏感，同样高斯核函数有了很多的变种，例如指数核核拉普拉斯核。

## 指数核

指数核是将高斯核中的向量的L2距离调整为L1距离，数学形式为$k(x,y) = exp(-\frac{||x-y||}{2\sigma ^2})$

这样的改动降低了对参数的敏感性，但适用范围相对较窄。

## 拉普拉斯核函数

拉普拉斯核函数完全等价于指数核，也是一种径向基核函数。
数学形式为$k(x,y) = exp(-\frac{||x-y||}{\sigma})$

## 卷积核



