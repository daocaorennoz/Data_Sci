
# 非平衡数据集的处理

## 问题

数据集中正负类样本比例严重不均衡，由此训练出来的模型泛化性能很差，在未知的数据集上性能很差。

## 方法

### 改变数据集的方法

#### 上采样Oversampling

是指重复在少数类中抽样，为了保持一定的比例关系，增加少数类的基数。

#### 下采样Upsampling

下采样是在多数类中进行抽样，为了保持一定的比例关系，只在多数类中取其一部分样本。

#### 生成合成数据Generating synthetic data

从少数类中持续创造新的合成数据来增加基数，代表性方法是SMOTE方法。

上述关于采样的方法，绕不开的是一个正负类样本的比例问题，不同的采样比例对模型的性能有着至关重要的影响，所以上述的方法要慎用。改变数据集的方法类似于篡改真实数据，所以使用起来需要更加慎重。

### 获得额外的特征

这种方法有别于上述的改变数据集的方法，该方法寄希望于寻找更多的额外特征，并且在这些额外特征上，数据可以显示出可区分性。

但我个人以为这种方法很难实用，如果很简单的可以获得这些特征，那么在原始数据中肯定已经引入了，所以这种方法必须对特征有相当深入的了解，并在了解之上，构造新的组合特征，来达到数据的可分性。当该方法可行时，比之于改变数据集的方法，该方法具有很大的优势。

### Cost-based Classification

考虑到误分类之后会导致的cost，来调整最后的预测输出。
从最高的预测准确性和召回变更为训练cost最小的模型。

考虑一个二分类任务，类别分别为C0和C1，假设C1是我们比较看重的类，如果不小心将C1误分类为C0，会带来很大损失，所以我们在不确定的时候更倾向于将类别判成C1，这是误分类所带来的cost是不对称的，asymmetric。

那么将c1误分类成c0的cost记为P01，反之记为P10，则有0 < P01 << P10,所以目标函数变为

![](https://github.com/daocaorennoz/Image/blob/master/imblance.bmp)

其中$C(\cdot)$是分类器，所以理论上最好的分类器为：

![](https://github.com/daocaorennoz/Image/blob/master/goodclassification.bmp)

### 类别权重再调整class reweight

cost-based的方法是在推断的时候用非对称的cost的方法来推断。

借鉴了这一思想，将非对称的cost与训练模型相结合。将训练的目标函数更改为带有threshold的目标函数，而不是简单的0.5，训练目标变为

$$\mathbb{P}(true\_C1|x)\times P 01+\mathbb{P}(true\_C0|x)\times P 10$$

在使用类似于Bayes classifier之类的模型时，可以根据$P 01$和$P 10$的比例关系，来对应调整C0和C1之间的关系。

假设$P 01 > P 10$,

则按照$P 01/P 10$的比例来进行上采样（少数类的基数应该乘以$P 01/P 10$，

或者按照$P 10/P 01$的比例来进行下采样（多数类的基数应该乘以$P 10/P 01$。


## 总结

- 不管使用哪种机器学习算法，我们都应该使用评估策略来评测得到的模型的性能。
- 当处理非平衡数据集时，如果我们的任务是得到最好的准确率，那么最好的分类器应该是朴素的，总是给出多数类的预测。
- 重采样技术应该要被谨慎考虑使用，并且最好不应该单独使用，而是配合问题的返工来达成特殊的目的。
- 问题的返工，通常是解决问题的最好的方式：分类器的决策规则是针对目标而特殊规定的，比如说最小化cost。

但我们并没有讨论类似于分层抽样的技术，这些方法在批训练的模型中会经常用到，并且一定程度上确保了模型的稳定性。