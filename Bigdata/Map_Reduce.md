

## 基本的海量数据处理技术
### 传统Hash

#### 方法
1. 将大数据或者大流量分散到N台机器中去，利用取模的方法。
2. 随机划分
3. 一致性hash算法，支持动态增长、更高级的划分算法

#### 应用

1. 流量分发，利用请求的key来进行hash分配。

### 分治

## 云计算的难点

单击系统变为分布式集群系统
稳定性和容错能力
数据一致性：强一致性、弱一致性。
难点：任何消息存在丢失的可能性、任何单机存在故障的可能性。

## MapReduce

一个用于处理海量数据的分布式计算框架。
框架解决了：
1. 数据分布式存储（HDFS）

2. 作业调度
3. 容错性
4. 机器间通行等复杂问题


分治思想：
map：分，将复杂的问题分解为若干简单的任务
reduce：合

mapreduce的执行过程：
数据输入->数据切分->map过程->reduce过程->输出结果 

map接收的是split好的数据，然后将数据进行操作，操作完后输出到缓冲区，在缓冲区进行按照key进行sort，然后进行归并排序，得到多个partition，然后将多个map输出的partition进行merge，然后进行reduce操作，得到结果。

### 两个很重要的进程
1. JobTracker
主进程，负责接受客户作业提交，调度任务到从节点上运行，并提高监控工作节点以及任务进度等管理功能，一个mapreduce集群中有一个jobtracker，一般运行在可靠的硬件上。
tasltracker通过心跳来向jobtracker通知其健康状态，包括可用的map和reduce任务数目、占用的数目以及运行中的任务详细信息。jobtracker通过一个线程池来同时对心跳和客户请求做处理。
2. TaskTracker
由jobtracker指派任务，实例化用户程序，在本地执行任务并周期性地像JobTracker回报状态，每个工作节点上只有一个JobTracker。

jobtracker一直等待jobclient提交任务，tasktracker每3秒钟向jobtracker发送心跳。

### 作业调度

默认模式为：先进先出FIFO
