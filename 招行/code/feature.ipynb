{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_name='data/FT_Camp_5/Train.csv'\n",
    "l_data = pd.read_csv(file_name,nrows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(file_name)\n",
    "data.set_index('stockcode',inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fig,ax=plt.subplots(1,2,figsize=(14,7))\n",
    "sns.countplot(x='fake',data=data,ax=ax[0])\n",
    "data['fake'].value_counts().plot(x=None,y=None,kind='pie',ax=ax[1],autopct='%1.2f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfraud=data.loc[data['fake']==1]\n",
    "Xnonfraud=data.loc[data['fake']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "correlationNonfraud=Xnonfraud.loc[:,data.columns!='fake'].corr()\n",
    "mask=np.zeros_like(correlationNonfraud)\n",
    "indices = np.triu_indices_from(correlationNonfraud)\n",
    "mask[indices]=True\n",
    "grid_kws={'width_ratios':(.9,.9,.05),'wspace':0.2}\n",
    "f,(ax1,ax2,cbar_ax)=plt.subplots(1,3,gridspec_kw=grid_kws,figsize=(20,10))\n",
    "cmap=sns.diverging_palette(220,8,as_cmap=True)\n",
    "ax1=sns.heatmap(correlationNonfraud,ax=ax1,vmin=-1,vmax=1,cmap=cmap,square=False,linewidths=0.5,mask=mask,cbar=False)\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(),size=16)\n",
    "ax1.set_yticklabels(ax1.get_yticklabels(),size=16)\n",
    "ax1.set_title('Normal',size=20)\n",
    "\n",
    "correlationfraud=Xfraud.loc[:,data.columns!='fake'].corr()\n",
    "# mask=np.zeros_like(correlationNonfraud)\n",
    "# indices = np.triu_indices_from(correlationNonfraud)\n",
    "# mask[indices]=True\n",
    "# grid_kws={'width_ratios':(.9,.9.,.05),'wspace':0.2}\n",
    "# f,(ax1,ax2,cbar_ax)=plt.subplots(1,3,gridspec_kw=grid_kws,figsize=(14,9))\n",
    "# cmap=sns.diverging_palette(220,8,as_cmap=True)\n",
    "ax2=sns.heatmap(correlationfraud,ax=ax2,vmin=-1,vmax=1,cmap=cmap,square=False,linewidths=0.5,mask=mask,yticklabels=False,cbar_ax=cbar_ax,cbar_kws={'orientation':'vertical','ticks':[-1,-0.5,0,0.5,1]})\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(),size=16)\n",
    "# ax1.set_yticklabels(ax1,get_yticklabels(),size=16)\n",
    "ax2.set_title('Fraud',size=20)\n",
    "cbar_ax.set_yticklabels(cbar_ax.get_yticklabels(),size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relationship between opinion and fraud\n",
    "f,(ax1,ax2)=plt.subplots(2,1,sharex=True,figsize=(16,4))\n",
    "bins=30\n",
    "ax1.hist(data['Opinion'][data.fake==1],bins=bins)\n",
    "ax1.set_title(\"Fraud\")\n",
    "ax2.hist(data['Opinion'][data.fake==0],bins=bins)\n",
    "ax2.set_title(\"Normal\")\n",
    "plt.xlabel('Opinion')\n",
    "plt.ylabel('Numbers')\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "# sns.factorplot(x='Opinion',data=data,kind='count',palette='ocean',size=5,aspect=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('fake').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec as gridspec\n",
    "v_feat=data.iloc[:,0:35].columns\n",
    "plt.figure(figsize=(16,28*4))\n",
    "gs=gridspec.GridSpec(35,1)\n",
    "for i,cn in enumerate(data[v_feat]):\n",
    "#     print(i,cn)\n",
    "    ax=plt.subplot(gs[i])\n",
    "    sns.distplot(data[cn][data.fake==1],bins=50)\n",
    "    sns.distplot(data[cn][data.fake==0],bins=100)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_title(str(cn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stay_col=['CA_ratio','Quick_ratio','TA_TO_ratio','Curr_ratio','OtherRec_to_Cur','Pre_to_Cur','Neg_Dednp_times','Monetary_to_Cur','CIP_ratio','fake']\n",
    "data_new=data[stay_col]\n",
    "data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# 进行特征放缩\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "sc = StandardScaler()\n",
    "# data_new.head().T\n",
    "x_feature=stay_col\n",
    "x_feature.remove('fake')\n",
    "data_new[x_feature]=sc.fit_transform(data_new[x_feature])\n",
    "x_val=data_new[x_feature]\n",
    "y_val=data_new['fake']\n",
    "names=data_new[x_feature].columns\n",
    "clf=RandomForestClassifier(n_estimators=10,random_state=123)\n",
    "clf.fit(x_val,y_val)\n",
    "# names, clf.feature_importances_\n",
    "for feature in zip(names,clf.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#未经过特征放缩\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "x_feature=stay_col\n",
    "x_feature.remove('fake')\n",
    "x_val=data_new[x_feature]\n",
    "y_val=data_new['fake']\n",
    "names=data_new[x_feature].columns\n",
    "clf=RandomForestClassifier(n_estimators=10,random_state=123)\n",
    "clf.fit(x_val,y_val)\n",
    "# names, clf.feature_importances_\n",
    "for feature in zip(names,clf.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['figure.figsize']=(12,6)\n",
    "importance = clf.feature_importances_\n",
    "feat_names =names\n",
    "indices=np.argsort(importance)[::-1]#dao xu\n",
    "fig=plt.figure(figsize=(20,6))\n",
    "plt.title('Feature importances by RandomForestClassifier')\n",
    "plt.bar(range(len(indices)),importance[indices],color='lightblue',align='center')\n",
    "plt.step(range(len(indices)),np.cumsum(importance[indices]),where='mid',label='CUmulative')\n",
    "plt.xticks(range(len(indices)),feat_names[indices],rotation='vertical',fontsize=14)\n",
    "plt.xlim([-1,len(indices)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data_new[x_feature]\n",
    "y=data_new['fake']\n",
    "\n",
    "n_sample =y.shape[0]\n",
    "n_pos_sample = y[y==0].shape[0]\n",
    "n_neg_sample = y[y==1].shape[0]\n",
    "print('样本个数：{}：正样本占{:.2%}：负样本占{:.2%}'.format(n_sample,n_pos_sample/n_sample,n_neg_sample/n_sample))\n",
    "print('特征维数:',X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X,y=sm.fit_sample(X,y)\n",
    "print('经过处理后：')\n",
    "n_sample = y.shape[0]\n",
    "n_pos_sample = y[y==0].shape[0]\n",
    "n_neg_sample = y[y==1].shape[0]\n",
    "print('样本个数：{}：正样本占{:.2%}：负样本占{:.2%}'.format(n_sample,n_pos_sample/n_sample,n_neg_sample/n_sample))\n",
    "print('特征维数:',X.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "lr = LogisticRegression(solver='liblinear',verbose=1)\n",
    "lr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted1 = lr.predict(X)\n",
    "print('Test set accuracy score:{:.5f}'.format(accuracy_score(predicted1,y,)))\n",
    "data_new[x_feature].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_test='data/FT_Camp_5/X_test.csv'\n",
    "test_data=pd.read_csv(file_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=test_data[x_feature]\n",
    "X_test[x_feature]=sc.fit_transform(X_test[x_feature])\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['fake']=lr.predict(X_test)\n",
    "X_test['stockcode']=test_data['stockcode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[['stockcode','fake']].to_csv('simple_lr.csv',sep=',',header=True,index=False,encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index('stockcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 该方案使用SMOTE来进行up sampling，使得原先不平衡数据样本个数：7653：正样本占98.58%：负样本占1.42%变成样本个数：15088：正样本占50.00%：负样本占50.00%，经过特征筛选\n",
    "# 具体为将特征与类别分布不一致的特征筛选出来\n",
    "# 选出['CA_ratio','Quick_ratio','TA_TO_ratio','Curr_ratio','OtherRec_to_Cur','Pre_to_Cur', 'Neg_Dednp_times','Monetary_to_Cur','CIP_ratio']\n",
    "# 流动资产比率，速动比率，总资产周转率，流动比率，其他应收款项占流动资产比例，预付款项占流动资产比例，最近三年扣非净利润为负的次数（包括今年），货币资金占流动资产比例，在建工程比率\n",
    "x_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.to_csv('Stan_fliter_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[stay_col].to_csv('fliter_data.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stay_col.append('fake')\n",
    "data[stay_col].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
